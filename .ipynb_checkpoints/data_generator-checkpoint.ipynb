{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    @author  jasonYu\n",
    "    @date    2017/6/3\n",
    "    @version created\n",
    "    @email   yuquanjie13@gmail.com\n",
    "'''\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import re\n",
    "sys.path.append('/home/yuquanjie/Documents/deep-direct-regression/tools')\n",
    "from point_check import point_in_polygon\n",
    "\n",
    "'''\n",
    "1. generate intput data\n",
    "    1.1 input image resizing, from (2400,3200) to (320,320)\n",
    "    1.2 (TODO) zero-center by mean pixel??\n",
    "    1.3 proprecess image\n",
    "2. generate output data\n",
    "    2.1 generate classification output data\n",
    "    2.2 (TODO) generate regression output data\n",
    "'''\n",
    "def get_train_data(all_imgs):\n",
    "    visulise = False\n",
    "    while True:\n",
    "        for img_data in all_imgs:      \n",
    "            print img_data['imagePath']\n",
    "            # image file wheater corresponding to text fle\n",
    "            annot = img_data['imagePath']\n",
    "            strinfo = re.compile('image/')\n",
    "            annot = strinfo.sub('text/',annot)\n",
    "            strinfo = re.compile('jpg')\n",
    "            annot = strinfo.sub('txt',annot)\n",
    "            \n",
    "            if os.path.isfile(img_data['imagePath']) and os.path.isfile(annot):\n",
    "                img = cv2.imread(img_data['imagePath'])\n",
    "                width = img.shape[0] #2400\n",
    "                height = img.shape[1] #3200\n",
    "\n",
    "                ## 1)generate input data\n",
    "                ### 1.1)input image, from (2400,3200) to (320,320)\n",
    "                img_320 = cv2.resize(img,(320,320),interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                ## 2)generate output data\n",
    "                ### 2.1)generate classification output data\n",
    "                divi_x = float(height) / 80.0\n",
    "                divi_y = float(width) / 80.0\n",
    "                #y_class_lable = -1 * np.ones((80,80)).astype(np.float32)\n",
    "                y_class_lable = -1 * np.ones((80,80))\n",
    "                for ix in xrange(y_class_lable.shape[0]):\n",
    "                    for jy in xrange(y_class_lable.shape[1]):\n",
    "                        for polygon in img_data['boxCoord']:\n",
    "                            x1 = string.atof(polygon[0]) / divi_x\n",
    "                            x2 = string.atof(polygon[2]) / divi_x\n",
    "                            x3 = string.atof(polygon[4]) / divi_x\n",
    "                            x4 = string.atof(polygon[6]) / divi_x\n",
    "\n",
    "                            y1 = string.atof(polygon[1]) / divi_y\n",
    "                            y2 = string.atof(polygon[3]) / divi_y\n",
    "                            y3 = string.atof(polygon[5]) / divi_y\n",
    "                            y4 = string.atof(polygon[7]) / divi_y\n",
    "\n",
    "                            polygon = [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]\n",
    "                            if point_in_polygon(ix,jy,polygon):\n",
    "                                y_class_lable[ix][jy] = 1\n",
    "                            #else:\n",
    "                            #    y_class_lable[ix][jy] = 0   \n",
    "\n",
    "                if visulise:\n",
    "                    if img_data['imagePath'] == '/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_100.jpg' :\n",
    "                        img = cv2.imread(img_data['imagePath'])\n",
    "                        img_80 = cv2.resize(img,(80,80),interpolation=cv2.INTER_CUBIC)\n",
    "                        img_draw = Image.fromarray(cv2.cvtColor(img_80,cv2.COLOR_BGR2RGB))\n",
    "                        draw = ImageDraw.Draw(img_draw)\n",
    "                        for coord in img_data['boxCoord']:\n",
    "                            print 'detail'\n",
    "                            print float(coord[0]) / divi_x, float(coord[1]) / divi_y\n",
    "                            print float(coord[2]) / divi_x, float(coord[3]) / divi_y\n",
    "                            print float(coord[4]) / divi_x, float(coord[5]) / divi_y\n",
    "                            print float(coord[6]) / divi_x, float(coord[7]) / divi_y\n",
    "                            print 'detail'\n",
    "                            draw.polygon([(float(coord[0]) / divi_x, float(coord[1]) / divi_y), \n",
    "                                          (float(coord[2]) / divi_x, float(coord[3]) / divi_y),\n",
    "                                          (float(coord[4]) / divi_x, float(coord[5]) / divi_y), \n",
    "                                          (float(coord[6]) / divi_x, float(coord[7]) / divi_y)],\n",
    "                                         outline = \"red\",fill=\"blue\")\n",
    "                        img_draw = np.array(img_draw)\n",
    "                        img_draw = cv2.cvtColor(img_draw, cv2.COLOR_RGB2BGR)\n",
    "                        one_locs = np.where(y_class_lable > 0)\n",
    "                        print one_locs\n",
    "                        print len(one_locs[0])\n",
    "                        print img_data['imagePath']\n",
    "                        print img_data['boxNum']\n",
    "                        cv2.imshow('img',img_draw)\n",
    "                        cv2.waitKey(0)        \n",
    "                \n",
    "                img_320 = np.expand_dims(img_320,axis = 0)\n",
    "                one_locs = np.where(y_class_lable > 0)\n",
    "                y_class_lable = np.expand_dims(y_class_lable,axis = 0)\n",
    "                y_class_lable = np.expand_dims(y_class_lable,axis = 3)\n",
    "                #yield np.copy(img_320), np.copy(y_class_lable), img_data\n",
    "                \n",
    "                ### 2.2)(TODO) generate regression output data\n",
    "                #y_regr_lable = np.zeros((80,80,8)).astype(np.float32)                   \n",
    "                y_regr_lable = np.zeros((80,80,8))\n",
    "                for i in xrange(len(one_locs[0])):\n",
    "                    # get quadrilateral vertex 4 corrdinates\n",
    "                    for polygon in img_data['boxCoord']:\n",
    "                        x1 = string.atof(polygon[0]) / divi_x\n",
    "                        x2 = string.atof(polygon[2]) / divi_x\n",
    "                        x3 = string.atof(polygon[4]) / divi_x\n",
    "                        x4 = string.atof(polygon[6]) / divi_x\n",
    "\n",
    "                        y1 = string.atof(polygon[1]) / divi_y\n",
    "                        y2 = string.atof(polygon[3]) / divi_y\n",
    "                        y3 = string.atof(polygon[5]) / divi_y\n",
    "                        y4 = string.atof(polygon[7]) / divi_y\n",
    "\n",
    "                        poly = [(x1,y1), (x2,y2), (x3,y3), (x4,y4)]\n",
    "                        ix = one_locs[0][i]\n",
    "                        jy = one_locs[1][i]\n",
    "                        if point_in_polygon(ix,jy,poly):\n",
    "                            left_top_x = poly[0][0]\n",
    "                            left_top_y = poly[0][1]\n",
    "                            righ_top_x = poly[1][0]\n",
    "                            righ_top_y = poly[1][1]\n",
    "\n",
    "                            righ_dow_x = poly[2][0]\n",
    "                            righ_dow_y = poly[2][1] \n",
    "                            left_dow_x = poly[3][0]\n",
    "                            left_dow_y = poly[3][1]\n",
    "\n",
    "                            y_regr_lable[ix][jy][0] = left_top_x * 4 - ix * 4\n",
    "                            y_regr_lable[ix][jy][1] = left_top_y * 4 - jy * 4\n",
    "                            y_regr_lable[ix][jy][2] = righ_top_x * 4 - ix * 4\n",
    "                            y_regr_lable[ix][jy][3] = righ_top_y * 4 - jy * 4\n",
    "\n",
    "                            y_regr_lable[ix][jy][4] = righ_dow_x * 4 - ix * 4\n",
    "                            y_regr_lable[ix][jy][5] = righ_dow_y * 4 - jy * 4\n",
    "                            y_regr_lable[ix][jy][6] = left_dow_x * 4 - ix * 4\n",
    "                            y_regr_lable[ix][jy][7] = left_dow_y * 4 - jy * 4\n",
    "                if visulise and img_data['imagePath'] == '/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_100.jpg' :\n",
    "                    print y_regr_lable[59][75]\n",
    "                    print y_regr_lable[59][76]\n",
    "                    print y_regr_lable[59][77]\n",
    "                y_regr_lable = np.expand_dims(y_regr_lable,axis = 0)\n",
    "                yield np.copy(img_320), np.copy(y_class_lable), np.copy(y_regr_lable), img_data\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "HUBER_DELTA = 1.0\n",
    "\n",
    "\n",
    "def smoothL1(y_true, y_pred):\n",
    "    #print y_pred.shape\n",
    "    import tensorflow as tf\n",
    "    #1. slice\n",
    "    #conTmp = tf.slice(y_true, [0, 0, 0, 8],[1, 80, 80, 1])\n",
    "    #2. concatenate\n",
    "    #tmp = tf.expand_dims(y_true[:, :, :, 8], 3)  page 27 helped by hl\n",
    "    tmp = tf.expand_dims(y_true[:, :, :, 8], 3)\n",
    "    #print tmp\n",
    "    \n",
    "    \n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    \n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    y_true = tf.concat([y_true, tmp], 3)\n",
    "    \n",
    "    #print y_true\n",
    "    x = K.abs(y_true[:, :, :, 0:8] - y_pred)\n",
    "    if K._BACKEND == 'tensorflow':\n",
    "        import tensorflow as tf\n",
    "        x = tf.where(tf.greater(HUBER_DELTA, x), \n",
    "                     0.5 * x ** 2, \n",
    "                     x - 0.5)\n",
    "        x = tf.where(tf.greater(y_true[:, :, :,8:16], 0),\n",
    "                     y_true[:, :, :,8:16],\n",
    "                     0 * y_true[:, :, :,8:16]) * x\n",
    "        #return  K.sum(x)\n",
    "        return  K.mean(x, axis = -1)\n",
    "#def mergeLoss():\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Add, Dense, Activation, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2DTranspose\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "def multi_task(input_tensor=None, trainable=False):\n",
    "    img_input = input_tensor\n",
    "    bn_axis = 3\n",
    "    \n",
    "    #conv_1\n",
    "    conv1_1 = Convolution2D(32, (5, 5), strides=(1,1), padding='same',\n",
    "                            activation='relu', name='conv1_1')(img_input)\n",
    "    pool1 = MaxPooling2D((2,2), strides=(2,2), name='pool1')(conv1_1)\n",
    "           \n",
    "    #conv_2\n",
    "    conv2_1 = Convolution2D(64, (3, 3), strides=(1,1), padding='same',\n",
    "                            activation='relu', name='conv2_1')(pool1)\n",
    "    conv2_2 = Convolution2D(64, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv2_2')(conv2_1)\n",
    "    pool2 = MaxPooling2D((2,2), strides=(2,2), name='pool2')(conv2_2)\n",
    "    \n",
    "    #conv_3    \n",
    "    conv3_1 = Convolution2D(128, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv3_1')(pool2)\n",
    "    conv3_2 = Convolution2D(128, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv3_2')(conv3_1)\n",
    "    pool3 = MaxPooling2D((2,2), strides=(2,2), name='pool3')(conv3_2)\n",
    "    pool3_for_fuse = Convolution2D(128, (1, 1), strides=(1,1), padding='same',\n",
    "                                   activation='relu', name='pool3_for_fuse')(pool3)\n",
    "    \n",
    "    #conv_4    \n",
    "    conv4_1 = Convolution2D(256, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv4_1')(pool3)\n",
    "    conv4_2 = Convolution2D(256, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv4_2')(conv4_1)\n",
    "    pool4 = MaxPooling2D((2,2), strides=(2,2), name='pool4')(conv4_2)\n",
    "    pool4_for_fuse = Convolution2D(128, (1, 1), strides=(1,1), padding='same',\n",
    "                                   activation='relu', name='pool4_for_fuse')(pool4)\n",
    "    \n",
    "    #conv_5    \n",
    "    conv5_1 = Convolution2D(512, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv5_1')(pool4)\n",
    "    conv5_2 = Convolution2D(512, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv5_2')(conv5_1)\n",
    "    pool5 = MaxPooling2D((2,2), strides=(2,2), name='pool5')(conv5_2)\n",
    "    pool5_for_fuse = Convolution2D(128, (1, 1), strides=(1,1), padding='same',\n",
    "                                   activation='relu', name='pool5_for_fuse')(pool5)\n",
    "    \n",
    "    #conv_6    \n",
    "    conv6_1 = Convolution2D(512, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv6_1')(pool5)\n",
    "    conv6_2 = Convolution2D(512, (3, 3), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv6_2')(conv6_1)\n",
    "    pool6 = MaxPooling2D((2,2), strides=(2,2), name='pool6')(conv6_2)\n",
    "    \n",
    "    #\n",
    "    conv7_1 = Convolution2D(128, (1, 1), strides=(1,1), padding='same', \n",
    "                            activation='relu', name='conv7_1')(pool6)\n",
    "    \n",
    "    upscore2 = Conv2DTranspose(filters=128, kernel_size=(2, 2),\n",
    "                              strides=(2, 2), padding='valid', use_bias=False,\n",
    "                             name='upscore2')(conv7_1)\n",
    "    \n",
    "    fuse_pool5 = add([upscore2, pool5_for_fuse])\n",
    "    upscore4 = Conv2DTranspose(filters=128, kernel_size=(2, 2),\n",
    "                              strides=(2, 2), padding='valid', use_bias=False,\n",
    "                             name='upscore4')(fuse_pool5)\n",
    "    fuse_pool4 = add([upscore4, pool4_for_fuse])\n",
    "       \n",
    "    upscore8 = Conv2DTranspose(filters=128, kernel_size=(2, 2),\n",
    "                              strides=(2, 2), padding='valid', use_bias=False,\n",
    "                             name='upscore8')(fuse_pool4)\n",
    "    fuse_pool3 = add([upscore8, pool3_for_fuse])\n",
    "    \n",
    "    upscore16 = Conv2DTranspose(filters=128, kernel_size=(2, 2),\n",
    "                              strides=(2, 2), padding='valid', use_bias=False,\n",
    "                             name='upscore16')(fuse_pool3)\n",
    "    ##########################################################################\n",
    "    ####### shared layer\n",
    "    ##########################################################################\n",
    "    x_clas = Convolution2D(1, (1, 1), strides=(1,1), padding='same', name='out_class')(upscore16)\n",
    "    x = Convolution2D(128, (1, 1), strides=(1,1), padding='same', activation='relu')(upscore16)\n",
    "    x = Convolution2D(8, (1, 1), strides=(1,1), padding='same', activation='sigmoid')(x)\n",
    "    x_regr = Lambda(lambda t: 800 * t - 400)(x)\n",
    "    #x_merge = Merge(x_)\n",
    "    return [x_clas, x_regr, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation files\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_0.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_100.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_101.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_102.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_103.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_104.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_105.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_106.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_107.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_108.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_109.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_10.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_110.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_111.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_112.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_113.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_114.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_115.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_116.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_117.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_118.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_119.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_11.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_120.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_121.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_122.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_123.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_124.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_125.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_126.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_127.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_128.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_129.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_12.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_130.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_131.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_132.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_133.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_134.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_135.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_136.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_137.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_138.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_139.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_13.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_140.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_141.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_142.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_143.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_144.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_145.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_146.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_147.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_148.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_149.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_14.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_150.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_151.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_152.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_153.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_154.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_155.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_156.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_157.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_158.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_159.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_15.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_160.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_161.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_162.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_163.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_164.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_165.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_166.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_167.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_168.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_169.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_16.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_170.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_171.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_172.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_173.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_174.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_175.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_176.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_177.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_178.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_179.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_17.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_180.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_181.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_182.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_183.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_184.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_185.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_186.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_187.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_188.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_189.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_18.jpg\n",
      "/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1/image/image_190.jpg\n",
      "reading data from trian_dataset_test.h5 \n",
      "(101, 320, 320, 3)\n",
      "(101, 80, 80, 1)\n",
      "(101, 80, 80, 9)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unrecognized keyword arguments: {'shuffer': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-de577a6df6b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mloss_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultask_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;31m#loss_class = multask_model.fit(X, Y, batch_size=5, epochs=500, verbose=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[0;32m   1395\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nb_epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1397\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized keyword arguments: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m         \u001b[1;31m# validate user data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized keyword arguments: {'shuffer': True}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from keras.layers import Input\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "from keras.models import Model\n",
    "import sys\n",
    "sys.path.append('/home/yuquanjie/Documents/deep-direct-regression/tools')\n",
    "from point_check import point_in_polygon\n",
    "from get_data import get_raw_data\n",
    "import os\n",
    "gpu_id = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(gpu_id)\n",
    "\n",
    "all_imgs, numFileTxt = get_raw_data('/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1')\n",
    "data_gen_train = get_train_data(all_imgs)\n",
    "\n",
    "img_input = Input((320,320,3))\n",
    "# Create model\n",
    "multi = multi_task(img_input,trainable=True)\n",
    "#multask_model = Model(img_input, multi[0:2])\n",
    "multask_model = Model(img_input, multi[1])\n",
    "#print multask_model.summary()\n",
    "sgd = optimizers.SGD(lr=0.01, decay=4e-4, momentum=0.9)\n",
    "# Compile model\n",
    "#multask_model.compile(loss=['hinge',smoothL1], optimizer=sgd)\n",
    "multask_model.compile(loss=[smoothL1], optimizer=sgd)\n",
    "\n",
    "if True:\n",
    "    X_train, Y_train_cls, Y_train_regr, Z  = data_gen_train.next()\n",
    "    Y_train_merge = np.concatenate([Y_train_regr, Y_train_cls], axis = 3)\n",
    "    for i in range (100):\n",
    "        X_train_iter, Y_train_cls_iter, Y_train_regr_iter, Z  = data_gen_train.next()\n",
    "\n",
    "        X_train = np.concatenate([X_train, X_train_iter], axis = 0)\n",
    "        Y_train_cls = np.concatenate([Y_train_cls, Y_train_cls_iter], axis = 0)\n",
    "\n",
    "        Y_train_merge_iter = np.concatenate([Y_train_regr_iter, Y_train_cls_iter], axis = 3)\n",
    "        Y_train_merge = np.concatenate([Y_train_merge, Y_train_merge_iter], axis = 0)\n",
    "\n",
    "\n",
    "X = X_train\n",
    "Y = [Y_train_cls, Y_train_merge]\n",
    "Y_1 = Y[0]\n",
    "Y_2 = Y[1]\n",
    "\n",
    "read_data = True\n",
    "if read_data:\n",
    "    # wirte data\n",
    "    file = h5py.File('trian_dataset_test.h5','w')\n",
    "    file.create_dataset('X_train',data = X_train)\n",
    "    file.create_dataset('Y_train_cls',data = Y_train_cls)\n",
    "    file.create_dataset('Y_train_merge',data = Y_train_merge)\n",
    "    file.close()   \n",
    "    # read data\n",
    "    print \"reading data from trian_dataset_test.h5 \"\n",
    "    file = h5py.File('trian_dataset_test.h5','r')\n",
    "    X = file['X_train'][:]\n",
    "    Y_1 = file['Y_train_cls'][:]\n",
    "    Y_2 = file['Y_train_merge'][:]\n",
    "    file.close()\n",
    "\n",
    "print X.shape\n",
    "print Y_1.shape\n",
    "print Y_2.shape\n",
    "Y = [Y_1, Y_2]\n",
    "# checkpoint \n",
    "filepath = \"/home/yuquanjie/Documents/deep-direct-regression/model/loss-decrease-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, \n",
    "                             save_best_only = True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "# Fit the model\n",
    "loss_class = multask_model.fit(X, Y_2, batch_size=5, epochs=500,callbacks = callbacks_list, verbose=1)\n",
    "#loss_class = multask_model.fit(X, Y, batch_size=5, epochs=500, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "from keras.layers import Input\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "from keras.models import Model, load_model\n",
    "import sys\n",
    "sys.path.append('/home/yuquanjie/Documents/deep-direct-regression/tools')\n",
    "from point_check import point_in_polygon\n",
    "from get_data import get_raw_data\n",
    "import os\n",
    "gpu_id = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=str(gpu_id)\n",
    "\n",
    "\n",
    "all_imgs, numFileTxt = get_raw_data('/home/yuquanjie/Documents/icdar2017rctw_train_v1.2/train/part1')\n",
    "data_gen_train = get_train_data(all_imgs)\n",
    "#######\n",
    "if True:\n",
    "    X_train, Y_train_cls, Y_train_regr, Z  = data_gen_train.next()\n",
    "    Y_train_merge = np.concatenate([Y_train_regr, Y_train_cls], axis = 3)\n",
    "    for i in range (0):\n",
    "        X_train_iter, Y_train_cls_iter, Y_train_regr_iter, Z  = data_gen_train.next()\n",
    "\n",
    "        X_train = np.concatenate([X_train, X_train_iter], axis = 0)\n",
    "        Y_train_cls = np.concatenate([Y_train_cls, Y_train_cls_iter], axis = 0)\n",
    "\n",
    "        Y_train_merge_iter = np.concatenate([Y_train_regr_iter, Y_train_cls_iter], axis = 3)\n",
    "        Y_train_merge = np.concatenate([Y_train_merge, Y_train_merge_iter], axis = 0)\n",
    "\n",
    "\n",
    "X = X_train\n",
    "print X.shape\n",
    "Y = [Y_train_cls, Y_train_merge]\n",
    "#######\n",
    "\n",
    "\n",
    "img_input = Input((320,320,3))\n",
    "# Create model\n",
    "multi = multi_task(img_input,trainable=True)\n",
    "multask_model = Model(img_input, multi[0:2])\n",
    "#print multask_model.summary()\n",
    "sgd = optimizers.SGD(lr=0.01, decay=4e-4, momentum=0.9)\n",
    "# Compile model\n",
    "multask_model.compile(loss=['hinge',smoothL1], optimizer=sgd)\n",
    "\n",
    "final_model = load_model('model/loss-decrease-999-4.07.hdf5', custom_objects={'smoothL1': smoothL1})\n",
    "P_result = final_model.predict_on_batch(X)\n",
    "print P_result[0].shape\n",
    "print P_result[1].shape\n",
    "print np.where(P_result[0][0, :, :, 0] > 0)\n",
    "np.set_printoptions(threshold=1e6)\n",
    "print P_result[1][0, :, :, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([[[2, 2, 2, 2], \n",
    "                 [3, 3, 3, 3], \n",
    "                 [4, 4, 4, 4]],\n",
    "                [[5, 5, 5, 5], \n",
    "                 [6, 6, 6, 6], \n",
    "                 [4, 4, 4, 4]]\n",
    "                ])\n",
    "los = tf.reduce_sum(a, -1)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(los))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
